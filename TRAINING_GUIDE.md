# ðŸ“š Ð ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð¾ Ð¿Ð¾ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ Ð½ÐµÐ¹Ñ€Ð¾ÑÐµÑ‚Ð¸

ÐŸÐ¾Ð´Ñ€Ð¾Ð±Ð½Ð°Ñ Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ Ð¿Ð¾ Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹ Ð²Ð¸Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð´Ñ€Ð¾Ð½Ð°.

## ðŸŽ¯ ÐžÐ±Ð·Ð¾Ñ€

ÐÐµÐ¹Ñ€Ð¾ÑÐµÑ‚ÑŒ Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð·Ð°Ð´Ð°Ñ‡Ñƒ ÑÐ¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹: Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ½Ð¸Ð¼ÐºÐ¾Ð¼ Ð´Ñ€Ð¾Ð½Ð° (Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚) Ð¸ Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ ÑÐ¿ÑƒÑ‚Ð½Ð¸ÐºÐ¾Ð²Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ð¾Ð¹.

## ðŸ—ï¸ ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¼Ð¾Ð´ÐµÐ»Ð¸

### Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸:

1. **Siamese Network** - Ð´Ð²Ðµ Ð¸Ð´ÐµÐ½Ñ‚Ð¸Ñ‡Ð½Ñ‹Ðµ ÑÐµÑ‚Ð¸ Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
2. **Triplet Network** - Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð½Ð° Ñ‚Ñ€Ð¾Ð¹ÐºÐ°Ñ… (anchor, positive, negative)
3. **ResNet50** - backbone Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²

### ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Feature Extractor:

```
Input Image (512x512x3)
  â†“
ResNet50 Backbone (pretrained on ImageNet)
  â†“
Global Average Pooling
  â†“
Linear(2048 â†’ 512) + ReLU + Dropout(0.5)
  â†“
Linear(512 â†’ 128) + BatchNorm
  â†“
L2 Normalization
  â†“
Output Features (128-dim vector)
```

## ðŸ“¦ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…

### 1. Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…

Ð¡Ð¾Ð·Ð´Ð°Ð¹Ñ‚Ðµ ÑÐ»ÐµÐ´ÑƒÑŽÑ‰ÑƒÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñƒ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¹:

```
data/
â””â”€â”€ processed/
    â””â”€â”€ pairs/
        â”œâ”€â”€ image_001_map.jpg      # Ð‘Ð¾Ð»ÑŒÑˆÐ°Ñ ÐºÐ°Ñ€Ñ‚Ð°
        â”œâ”€â”€ image_001_drone.jpg    # Ð¡Ð½Ð¸Ð¼Ð¾Ðº Ð´Ñ€Ð¾Ð½Ð°
        â”œâ”€â”€ image_002_map.jpg
        â”œâ”€â”€ image_002_drone.jpg
        ...
```

### 2. Ð¡Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ…

#### Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸ ÑÐ¿ÑƒÑ‚Ð½Ð¸ÐºÐ¾Ð²Ñ‹Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹:

- **Google Earth** - Ð¼Ð¾Ð¶Ð½Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ ÑÐºÑ€Ð¸Ð½ÑˆÐ¾Ñ‚Ñ‹
- **OpenStreetMap** - Ð±ÐµÑÐ¿Ð»Ð°Ñ‚Ð½Ñ‹Ðµ ÐºÐ°Ñ€Ñ‚Ñ‹
- **Sentinel Hub** - ÑÐ¿ÑƒÑ‚Ð½Ð¸ÐºÐ¾Ð²Ñ‹Ðµ ÑÐ½Ð¸Ð¼ÐºÐ¸ ESA
- **Ð‘Ð¸Ð½Ð³ ÐšÐ°Ñ€Ñ‚Ñ‹** - Ð²Ñ‹ÑÐ¾ÐºÐ¾Ðµ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ
- **Ð¯Ð½Ð´ÐµÐºÑ ÐšÐ°Ñ€Ñ‚Ñ‹** - Ð´Ð»Ñ Ð Ð¾ÑÑÐ¸Ð¸

#### Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¿Ð°Ñ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹:

**Map Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (Ð±Ð¾Ð»ÑŒÑˆÐ°Ñ ÐºÐ°Ñ€Ñ‚Ð°):**
- Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ: Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 2048x2048 Ð¿Ð¸ÐºÑÐµÐ»ÐµÐ¹
- ÐžÑ…Ð²Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð±Ð¾Ð»ÑŒÑˆÑƒÑŽ Ñ‚ÐµÑ€Ñ€Ð¸Ñ‚Ð¾Ñ€Ð¸ÑŽ
- Ð¢Ð¸Ð¿Ñ‹ Ð¼ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸: Ð³Ð¾Ñ€Ð¾Ð´, Ð»ÐµÑ, Ð²Ð¾Ð´Ð°, Ð¿Ð¾Ð»Ñ, Ð´Ð¾Ñ€Ð¾Ð³Ð¸

**Drone Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ (ÑÐ½Ð¸Ð¼Ð¾Ðº Ð´Ñ€Ð¾Ð½Ð°):**
- Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ: 512x512 Ð¸Ð»Ð¸ 1024x1024
- Ð’Ñ‹Ñ€ÐµÐ·Ð°Ð½Ð½Ñ‹Ð¹ Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚ Ð¸Ð· ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ¹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ ÐºÐ°Ñ€Ñ‚Ñ‹
- ÐœÐ¾Ð¶ÐµÑ‚ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ñ‚ÑŒ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ (Ð¿Ð¾Ð²Ð¾Ñ€Ð¾Ñ‚, Ð¼Ð°ÑÑˆÑ‚Ð°Ð±)

### 3. Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°

```python
import cv2
import numpy as np
from PIL import Image
import os

def create_synthetic_pairs(map_image_path, output_dir, num_pairs=100):
    """
    Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ¸Ð½Ñ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ñ… Ð¿Ð°Ñ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¸Ð· ÐºÐ°Ñ€Ñ‚Ñ‹.
    
    Args:
        map_image_path: ÐŸÑƒÑ‚ÑŒ Ðº Ð±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ ÐºÐ°Ñ€Ñ‚Ðµ
        output_dir: Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¿Ð°Ñ€
        num_pairs: ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ð°Ñ€ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ
    """
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° ÐºÐ°Ñ€Ñ‚Ñ‹
    map_img = cv2.imread(map_image_path)
    map_img = cv2.cvtColor(map_img, cv2.COLOR_BGR2RGB)
    h, w = map_img.shape[:2]
    
    os.makedirs(output_dir, exist_ok=True)
    
    for i in range(num_pairs):
        # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ñ Ð´Ð»Ñ Ð²Ñ‹Ñ€ÐµÐ·ÐºÐ¸
        y = np.random.randint(0, h - 512)
        x = np.random.randint(0, w - 512)
        
        # Ð’Ñ‹Ñ€ÐµÐ·ÐºÐ° Ñ„Ñ€Ð°Ð³Ð¼ÐµÐ½Ñ‚Ð°
        patch = map_img[y:y+512, x:x+512]
        
        # ÐŸÑ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¹ Ð´Ð»Ñ drone Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
        drone_patch = augment_drone_image(patch.copy())
        
        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ
        cv2.imwrite(
            os.path.join(output_dir, f"image_{i:03d}_map.jpg"),
            map_img
        )
        cv2.imwrite(
            os.path.join(output_dir, f"image_{i:03d}_drone.jpg"),
            drone_patch
        )

def augment_drone_image(image):
    """ÐÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ñ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¸Ð¼Ð¸Ñ‚Ð°Ñ†Ð¸Ð¸ ÑÐ½Ð¸Ð¼ÐºÐ° Ð´Ñ€Ð¾Ð½Ð°."""
    # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ Ð¿Ð¾Ð²Ð¾Ñ€Ð¾Ñ‚
    angle = np.random.randint(-15, 15)
    h, w = image.shape[:2]
    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
    image = cv2.warpAffine(image, M, (w, h))
    
    # Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ð°Ñ ÑÑ€ÐºÐ¾ÑÑ‚ÑŒ/ÐºÐ¾Ð½Ñ‚Ñ€Ð°ÑÑ‚
    brightness = np.random.randint(-20, 20)
    contrast = np.random.uniform(0.9, 1.1)
    image = cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)
    
    # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÑˆÑƒÐ¼Ð°
    noise = np.random.randn(*image.shape) * 5
    image = np.clip(image.astype(float) + noise, 0, 255).astype(np.uint8)
    
    return image
```

### 4. Ð¢Ð¸Ð¿Ñ‹ Ð¼ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

ÐžÐ±ÑÐ·Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²ÐºÐ»ÑŽÑ‡Ð¸Ñ‚Ðµ Ð² Ð´Ð°Ñ‚Ð°ÑÐµÑ‚:

- âœ… **Ð“Ð¾Ñ€Ð¾Ð´**: Ð·Ð´Ð°Ð½Ð¸Ñ, ÑƒÐ»Ð¸Ñ†Ñ‹, Ð¿Ð°Ñ€ÐºÐ¾Ð²ÐºÐ¸
- âœ… **Ð›ÐµÑ**: Ð´ÐµÑ€ÐµÐ²ÑŒÑ, Ñ‚Ñ€Ð¾Ð¿Ñ‹
- âœ… **Ð’Ð¾Ð´Ð¾ÐµÐ¼Ñ‹**: Ð¾Ð·ÐµÑ€Ð°, Ñ€ÐµÐºÐ¸, Ð¿Ñ€ÑƒÐ´Ñ‹
- âœ… **ÐŸÐ¾Ð»Ñ**: ÑÐµÐ»ÑŒÑÐºÐ¾Ñ…Ð¾Ð·ÑÐ¹ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ ÑƒÐ³Ð¾Ð´ÑŒÑ
- âœ… **Ð”Ð¾Ñ€Ð¾Ð³Ð¸**: Ð°ÑÑ„Ð°Ð»ÑŒÑ‚, Ñ€Ð°Ð·Ð¼ÐµÑ‚ÐºÐ°
- âœ… **Ð¡Ð¼ÐµÑˆÐ°Ð½Ð½Ð°Ñ Ð¼ÐµÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ**: ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð°Ñ†Ð¸Ð¸ Ð²Ñ‹ÑˆÐµÐ¿ÐµÑ€ÐµÑ‡Ð¸ÑÐ»ÐµÐ½Ð½Ð¾Ð³Ð¾

**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ð¾Ðµ Ñ€Ð°ÑÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ:**
- Ð“Ð¾Ñ€Ð¾Ð´: 30%
- Ð›ÐµÑ: 25%
- Ð’Ð¾Ð´Ð¾ÐµÐ¼Ñ‹: 15%
- ÐŸÐ¾Ð»Ñ: 20%
- Ð”Ð¾Ñ€Ð¾Ð³Ð¸: 10%

## ðŸš€ ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸

### 1. ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

ÐžÑ‚Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ `config/train_config.yaml`:

```yaml
training:
  use_triplet: true  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ triplet loss
  batch_size: 32
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
```

### 2. Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

```bash
# Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿ÑƒÑÐº
python src/training/train.py --config config/train_config.yaml

# Ð¡ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¼Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸
python src/training/train.py \
    --config config/train_config.yaml \
    --batch-size 64 \
    --num-epochs 200
```

### 3. ÐœÐ¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ

Ð’Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð²Ñ‹Ð²Ð¾Ð´ÑÑ‚ÑÑ:
- Training Loss
- Validation Loss
- Validation Accuracy

**ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ:**
- Val Accuracy: > 85% (Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾)
- Val Accuracy: > 90% (Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾)
- Val Loss: < 0.3 (Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾)

### 4. Checkpoint'Ñ‹

ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐµÑ‚ÑÑ Ð² `models/checkpoints/`:
- `last_checkpoint.pth` - Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ð¹ checkpoint
- `best_model.pth` - Ð»ÑƒÑ‡ÑˆÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸

## ðŸ” Loss Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸

### Triplet Loss

```
L = max(0, margin + D(a,p) - D(a,n))
```

Ð“Ð´Ðµ:
- `a` - anchor (ÑÐ½Ð¸Ð¼Ð¾Ðº Ð´Ñ€Ð¾Ð½Ð°)
- `p` - positive (Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð°Ñ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ñ‹)
- `n` - negative (Ð½ÐµÐ¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð°Ñ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ ÐºÐ°Ñ€Ñ‚Ñ‹)
- `margin` - Ð¾Ñ‚ÑÑ‚ÑƒÐ¿ (Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ 1.0)

### Contrastive Loss

```
L = (1-y) * DÂ² + y * max(0, margin - D)Â²
```

Ð“Ð´Ðµ `y=1` Ð´Ð»Ñ Ð¿Ð¾Ñ…Ð¾Ð¶Ð¸Ñ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, `y=0` Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ….

**Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ñ:** Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ Triplet Loss Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ³Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°.

## ðŸ“Š ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð°

### 1. Ð¢Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¾Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ

Ð Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼ÐµÐ¶Ð´Ñƒ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¸ Ð¸ÑÑ‚Ð¸Ð½Ð½Ñ‹Ð¼Ð¸ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼Ð¸:
- **Excellent:** < 10 Ð¼ÐµÑ‚Ñ€Ð¾Ð²
- **Good:** 10-50 Ð¼ÐµÑ‚Ñ€Ð¾Ð²
- **Fair:** 50-100 Ð¼ÐµÑ‚Ñ€Ð¾Ð²
- **Poor:** > 100 Ð¼ÐµÑ‚Ñ€Ð¾Ð²

### 2. Validation Accuracy

ÐŸÑ€Ð¾Ñ†ÐµÐ½Ñ‚ triplets, Ð³Ð´Ðµ distance(anchor, positive) < distance(anchor, negative)

### 3. Inference Time

Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾Ð´Ð½Ð¾Ð³Ð¾ ÑÐ½Ð¸Ð¼ÐºÐ°:
- **Target:** < 2 ÑÐµÐºÑƒÐ½Ð´Ñ‹
- **Optimal:** < 1 ÑÐµÐºÑƒÐ½Ð´Ð°

## âš™ï¸ Ð“Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹

### ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹:

1. **Learning Rate**: 0.001 (Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ 0.0005)
2. **Batch Size**: 32 (Ð±Ð¾Ð»ÑŒÑˆÐµ = ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½ÐµÐµ, Ð½Ð¾ Ð½ÑƒÐ¶Ð½Ð° Ð¿Ð°Ð¼ÑÑ‚ÑŒ)
3. **Feature Dim**: 128 (Ð±Ð¾Ð»ÑŒÑˆÐµ = Ñ‚Ð¾Ñ‡Ð½ÐµÐµ, Ð½Ð¾ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½ÐµÐµ)
4. **Margin**: 1.0 (Ð´Ð»Ñ triplet loss)
5. **Image Size**: 512x512 (Ð±Ð¾Ð»ÑŒÑˆÐµ = Ñ‚Ð¾Ñ‡Ð½ÐµÐµ, Ð½Ð¾ Ð¼ÐµÐ´Ð»ÐµÐ½Ð½ÐµÐµ)

### Scheduler:

```yaml
scheduler:
  type: "cosine"  # ÐŸÐ»Ð°Ð²Ð½Ð¾Ðµ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐµÐ½Ð¸Ðµ LR
  eta_min: 0.00001
```

## ðŸŽ¨ ÐÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…

ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÑŽÑ‚ÑÑ Ðº drone Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑÐ¼:

- âœ… Random Rotation (Â±15Â°)
- âœ… Horizontal/Vertical Flip
- âœ… Brightness (Â±20%)
- âœ… Contrast (Â±20%)
- âœ… Hue/Saturation/Value shifts
- âœ… Gaussian Noise
- âœ… Color Jitter

**Ð’Ð°Ð¶Ð½Ð¾:** ÐÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸ Ð´ÐµÐ»Ð°ÑŽÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ robust Ðº Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÐ¼ Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ñ Ð¸ Ð¿Ð¾Ð³Ð¾Ð´Ñ‹.

## ðŸ”„ Transfer Learning

ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ Ð¿Ñ€ÐµÐ´Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð½Ñ‹Ð¹ ResNet50 Ð½Ð° ImageNet:

```python
pretrained=True  # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ ImageNet weights
```

Ð­Ñ‚Ð¾ ÑƒÑÐºÐ¾Ñ€ÑÐµÑ‚ ÑÑ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð¸ ÑƒÐ»ÑƒÑ‡ÑˆÐ°ÐµÑ‚ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾.

## ðŸ“ˆ ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ

### Ð•ÑÐ»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð¾Ð±ÑƒÑ‡Ð°ÐµÑ‚ÑÑ:

1. Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ learning rate Ð² 2 Ñ€Ð°Ð·Ð°
2. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ batch size
3. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ñ…
4. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¹

### Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ:

1. Ð£Ð²ÐµÐ»Ð¸Ñ‡ÑŒÑ‚Ðµ dropout (0.5 â†’ 0.7)
2. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ weight decay
3. Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚Ðµ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸
4. Ð”Ð¾Ð±Ð°Ð²ÑŒÑ‚Ðµ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ…

## ðŸ§ª Ð¢ÐµÑÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ

### 1. Ð¢ÐµÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚

ÐŸÐ¾ÑÐ»Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¿Ñ€Ð¾Ñ‚ÐµÑÑ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð½Ð° Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ñ‚ÐµÑÑ‚Ð¾Ð²Ð¾Ð¼ Ð½Ð°Ð±Ð¾Ñ€Ðµ:

```python
# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ñ‚ÐµÑÑ‚Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
test_dataset = TripletMapDataset(
    data_dir="data/processed",
    mode="test"
)

# ÐžÑ†ÐµÐ½ÐºÐ°
accuracy, distance_error = evaluate_model(model, test_dataset)
```

### 2. Ð˜Ð½Ñ„ÐµÑ€ÐµÐ½Ñ Ð½Ð° Ð½Ð¾Ð²Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…

```python
from src.inference import ImageMatcher

# Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸
model = load_model("models/checkpoints/best_model.pth")
matcher = ImageMatcher(model)

# ÐŸÐ¾Ð¸ÑÐº ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ð¹
matches = matcher.match_using_sliding_window(
    drone_image,
    map_image,
    window_size=(512, 512)
)
```

## ðŸ“ Checklist Ð¿Ð¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…

- [ ] Ð¡Ð¾Ð±Ñ€Ð°Ð½Ð¾ Ð¼Ð¸Ð½Ð¸Ð¼ÑƒÐ¼ 1000 Ð¿Ð°Ñ€ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
- [ ] Ð’ÐºÐ»ÑŽÑ‡ÐµÐ½Ñ‹ Ð²ÑÐµ Ñ‚Ð¸Ð¿Ñ‹ Ð¼ÐµÑÑ‚Ð½Ð¾ÑÑ‚Ð¸
- [ ] Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ map Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ â‰¥ 2048x2048
- [ ] Ð Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ drone Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ = 512x512
- [ ] Ð”Ð°Ð½Ð½Ñ‹Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ñ‹ Ð½Ð° train/val/test (80/10/10)
- [ ] ÐŸÑ€Ð¾Ð²ÐµÑ€ÐµÐ½Ð¾ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹
- [ ] Ð£Ð´Ð°Ð»ÐµÐ½Ñ‹ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ñ‹
- [ ] Ð¡Ð¾Ð·Ð´Ð°Ð½Ñ‹ Ð°ÑƒÐ³Ð¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸Ð¸

## ðŸŽ“ Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´Ð°Ñ†Ð¸Ð¸

1. **ÐÐ°Ñ‡Ð½Ð¸Ñ‚Ðµ Ñ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¾Ð³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð°** (100-200 Ð¿Ð°Ñ€) Ð´Ð»Ñ Ð¾Ñ‚Ð»Ð°Ð´ÐºÐ¸
2. **Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹Ñ‚Ðµ GPU** Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ (GTX 1080 Ð¸Ð»Ð¸ Ð»ÑƒÑ‡ÑˆÐµ)
3. **Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐ¹Ñ‚Ðµ Ð»Ð¾Ð³Ð¸** Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
4. **Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹** Ð½Ð° val Ð´Ð°Ð½Ð½Ñ‹Ñ…
5. **Ð­ÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ** Ñ Ð³Ð¸Ð¿ÐµÑ€Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ð°Ð¼Ð¸

## ðŸ“š Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ€ÐµÑÑƒÑ€ÑÑ‹

- [PyTorch Documentation](https://pytorch.org/docs/)
- [Siamese Networks Explained](https://towardsdatascience.com/learning-similarity-in-computer-vision-part-1-siamese-networks-intro-and-theory-1c8c6c087c92)
- [Triplet Loss Explained](https://omoindrot.github.io/triplet-loss)

## ðŸ¤ ÐŸÐ¾Ð´Ð´ÐµÑ€Ð¶ÐºÐ°

ÐŸÑ€Ð¸ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ½Ð¾Ð²ÐµÐ½Ð¸Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼:
1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð»Ð¾Ð³Ð¸ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
2. Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
3. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ ÑƒÐ¼ÐµÐ½ÑŒÑˆÐ¸Ñ‚ÑŒ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»Ð¸
4. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑŒÑ‚Ðµ Ð½Ð°Ð»Ð¸Ñ‡Ð¸Ðµ GPU Ð¿Ð°Ð¼ÑÑ‚Ð¸

---

**Ð£Ð´Ð°Ñ‡Ð¸ Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ð¸! ðŸš€**
